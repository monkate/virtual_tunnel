{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac57f8e-214a-4c37-904f-37d592f3e532",
   "metadata": {},
   "source": [
    "### Merge 4 annotation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d08200-b535-42de-9d2c-0b3c3b321c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "import os  \n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def parse_cvat_xml(xml_paths):\n",
    "    \"\"\"\n",
    "    Parsing one or more XML CVAT files with tags\n",
    "    Handles duplicate image IDs correctly\n",
    "    \n",
    "    Parameters:\n",
    "        xml_paths (str or list): The path to the XML file or a list of paths\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Combined dataframe with unique images\n",
    "    \"\"\"\n",
    "    if isinstance(xml_paths, str):\n",
    "        xml_paths = [xml_paths]\n",
    "    \n",
    "    all_data = []\n",
    "    seen_names = set()  # To track unique image names\n",
    "    \n",
    "    for xml_path in xml_paths:\n",
    "        try:\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            for image in root.findall('image'):\n",
    "                img_name = image.get('name')\n",
    "                if not img_name:\n",
    "                    continue\n",
    "                    \n",
    "                # Skip it if you've already seen the image.\n",
    "                if img_name in seen_names:\n",
    "                    continue\n",
    "                \n",
    "                # Getting all the tags for the image\n",
    "                tags = []\n",
    "                for tag in image.findall('tag'):\n",
    "                    label = tag.get('label')\n",
    "                    if label and label.lower() in ['forward', 'backward', 'other']:\n",
    "                        tags.append(label.lower())\n",
    "                \n",
    "                if tags:\n",
    "                    # We take the first label if there are several of them\n",
    "                    all_data.append({\n",
    "                        'image': img_name,\n",
    "                        'label': tags[0],\n",
    "                        'source_file': os.path.basename(xml_path),\n",
    "                        'width': image.get('width'),\n",
    "                        'height': image.get('height')\n",
    "                    })\n",
    "                    seen_names.add(img_name)\n",
    "        \n",
    "        except ET.ParseError as e:\n",
    "            print(f\"Parsing error {xml_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_data:\n",
    "        raise ValueError(\"No images with correct labels were found.\")\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "df_merged = parse_cvat_xml([r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\analysis\\classificator\\annotations_3.xml\",r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\analysis\\classificator\\annotations_1.xml\", r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\analysis\\classificator\\annotations.xml\", r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\analysis\\classificator\\annotations_2.xml\"])\n",
    "\n",
    "print(f\"Total unique images: {len(df_merged)}\")\n",
    "print(\"Distribution by tags:\")\n",
    "print(df_merged['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3734c279-95e9-4ca2-95c9-237899084b89",
   "metadata": {},
   "source": [
    "### Train model for 909 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327282e9-074c-428f-aaa2-109adc8bd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def parse_cvat_xml(xml_path):\n",
    "    \"\"\"XML CAT parsing with tags\"\"\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    data = []\n",
    "    for image in root.findall('image'):\n",
    "        img_name = image.get('name')\n",
    "        if not img_name:\n",
    "            continue\n",
    "            \n",
    "        for tag in image.findall('tag'):\n",
    "            label = tag.get('label')\n",
    "            if label and label.lower() in ['forward', 'backward', 'other']:\n",
    "                data.append({\n",
    "                    'image': img_name,\n",
    "                    'label': label.lower()\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def load_and_preprocess_data(df, img_dir, img_size=(128, 128)):\n",
    "    \"\"\"Optimized image loading\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {'forward': 0, 'backward': 1, 'other': 2}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        img_path = os.path.join(img_dir, row['image'])\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, img_size)\n",
    "            images.append(img)\n",
    "            labels.append(label_map[row['label']])\n",
    "    \n",
    "    return np.array(images, dtype=np.float32) / 255.0, np.array(labels)\n",
    "\n",
    "def create_optimized_model(input_shape=(128, 128, 3)):\n",
    "    \"\"\"Optimized architecture\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    XML_PATH = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\analysis\\classificator\\annotations.xml\"\n",
    "    IMG_DIR = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\"\n",
    "    MODEL_PATH = 'bee_classifier_909.keras'\n",
    "    \n",
    "    # 1. Loading data\n",
    "    df = df_merged\n",
    "    print(\"Class distribution:\\n\", df['label'].value_counts())\n",
    "    \n",
    "    # 2. Preparing data\n",
    "    X, y = load_and_preprocess_data(df, IMG_DIR)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # 3. Balancing classes\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        'balanced', classes=np.unique(y), y=y)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    print(\"Class weights:\", class_weights)\n",
    "    \n",
    "    # 4. Conservative augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=5,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        zoom_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='constant'\n",
    "    )\n",
    "    \n",
    "    # 5. Creating and training model\n",
    "    model = create_optimized_model()\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5)\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nModel training...\")\n",
    "    history = model.fit(\n",
    "        datagen.flow(X_train, y_train, batch_size=16),\n",
    "        epochs=50,\n",
    "        validation_data=(X_test, y_test),\n",
    "        class_weight=class_weights,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 6. Estimation\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"\\nFinal accuracy: {test_acc:.4f}\")\n",
    "    model.save(MODEL_PATH)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cabcdb4-e7d7-4221-819c-af59257d4cbf",
   "metadata": {},
   "source": [
    "### Train model for 785 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2447fa9-ef05-4383-8ab4-e63abbf08837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def parse_cvat_xml(xml_path):\n",
    "    \"\"\"XML CAT parsing with tags\"\"\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    data = []\n",
    "    for image in root.findall('image'):\n",
    "        img_name = image.get('name')\n",
    "        if not img_name:\n",
    "            continue\n",
    "            \n",
    "        for tag in image.findall('tag'):\n",
    "            label = tag.get('label')\n",
    "            if label and label.lower() in ['forward', 'backward', 'other']:\n",
    "                data.append({\n",
    "                    'image': img_name,\n",
    "                    'label': label.lower()\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def load_and_preprocess_data(df, img_dir, img_size=(128, 128)):\n",
    "    \"\"\"Optimized image loading\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {'forward': 0, 'backward': 1, 'other': 2}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        img_path = os.path.join(img_dir, row['image'])\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, img_size)\n",
    "            images.append(img)\n",
    "            labels.append(label_map[row['label']])\n",
    "    \n",
    "    return np.array(images, dtype=np.float32) / 255.0, np.array(labels)\n",
    "\n",
    "def create_optimized_model(input_shape=(128, 128, 3)):\n",
    "    \"\"\"Optimized architecture\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    XML_PATH = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\analysis\\classificator\\annotations.xml\"\n",
    "    IMG_DIR = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\"\n",
    "    MODEL_PATH = 'bee_classifier_new.keras'\n",
    "    \n",
    "    # 1. Loading data\n",
    "    df = df_merged\n",
    "    print(\"Class distribution:\\n\", df['label'].value_counts())\n",
    "    \n",
    "    # 2. Preparing data\n",
    "    X, y = load_and_preprocess_data(df, IMG_DIR)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # 3. Balancing classes\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        'balanced', classes=np.unique(y), y=y)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    print(\"Class weights:\", class_weights)\n",
    "    \n",
    "    # 4. Conservative augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=5,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        zoom_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='constant'\n",
    "    )\n",
    "    \n",
    "    # 5. Creating and training model\n",
    "    model = create_optimized_model()\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5)\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nModel training...\")\n",
    "    history = model.fit(\n",
    "        datagen.flow(X_train, y_train, batch_size=16),\n",
    "        epochs=50,\n",
    "        validation_data=(X_test, y_test),\n",
    "        class_weight=class_weights,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 6. Estimation\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"\\nFinal accuracy: {test_acc:.4f}\")\n",
    "    model.save(MODEL_PATH)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf8fc3-40b4-4673-8966-a9ad94cc167a",
   "metadata": {},
   "source": [
    "### Train model for 553 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b1250-39da-4d4e-8760-c8dbeeee25c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def parse_cvat_xml(xml_path):\n",
    "    \"\"\"XML CAT parsing with tags\"\"\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    data = []\n",
    "    for image in root.findall('image'):\n",
    "        img_name = image.get('name')\n",
    "        if not img_name:\n",
    "            continue\n",
    "            \n",
    "        for tag in image.findall('tag'):\n",
    "            label = tag.get('label')\n",
    "            if label and label.lower() in ['forward', 'backward', 'other']:\n",
    "                data.append({\n",
    "                    'image': img_name,\n",
    "                    'label': label.lower()\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def load_and_preprocess_data(df, img_dir, img_size=(128, 128)):\n",
    "    \"\"\"Optimized image loading\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {'forward': 0, 'backward': 1, 'other': 2}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        img_path = os.path.join(img_dir, row['image'])\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, img_size)\n",
    "            images.append(img)\n",
    "            labels.append(label_map[row['label']])\n",
    "    \n",
    "    return np.array(images, dtype=np.float32) / 255.0, np.array(labels)\n",
    "\n",
    "def create_optimized_model(input_shape=(128, 128, 3)):\n",
    "    \"\"\"Optimized architecture\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    XML_PATH = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\analysis\\classificator\\annotations.xml\"\n",
    "    IMG_DIR = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\"\n",
    "    MODEL_PATH = 'bee_classifier_optimized.keras'\n",
    "    \n",
    "    # 1. Data loading\n",
    "    df = df_merged\n",
    "    print(\"Class distribution:\\n\", df['label'].value_counts())\n",
    "    \n",
    "    # 2. Preparing data\n",
    "    X, y = load_and_preprocess_data(df, IMG_DIR)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # 3. Balancing classes\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        'balanced', classes=np.unique(y), y=y)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    print(\"Class weights:\", class_weights)\n",
    "    \n",
    "    # 4. Conservative augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=5,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        zoom_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='constant'\n",
    "    )\n",
    "    \n",
    "    # 5. Creating and training model\n",
    "    model = create_optimized_model()\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5)\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nData training...\")\n",
    "    history = model.fit(\n",
    "        datagen.flow(X_train, y_train, batch_size=16),\n",
    "        epochs=50,\n",
    "        validation_data=(X_test, y_test),\n",
    "        class_weight=class_weights,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 6. Estimation\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"\\nFinal accuracy: {test_acc:.4f}\")\n",
    "    model.save(MODEL_PATH)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18f240c-4ad2-4874-a192-0ef487462263",
   "metadata": {},
   "source": [
    "### Train model for 390 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1327df3c-5f69-402a-98f1-1e7fe2dfca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def parse_cvat_xml(xml_path):\n",
    "    \"\"\"XML CAT parsing with tags\"\"\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    data = []\n",
    "    for image in root.findall('image'):\n",
    "        img_name = image.get('name')\n",
    "        if not img_name:\n",
    "            continue\n",
    "            \n",
    "        for tag in image.findall('tag'):\n",
    "            label = tag.get('label')\n",
    "            if label and label.lower() in ['forward', 'backward', 'other']:\n",
    "                data.append({\n",
    "                    'image': img_name,\n",
    "                    'label': label.lower()\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def load_and_preprocess_data(df, img_dir, img_size=(128, 128)):\n",
    "    \"\"\"Optimized image loading\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {'forward': 0, 'backward': 1, 'other': 2}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        img_path = os.path.join(img_dir, row['image'])\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, img_size)\n",
    "            images.append(img)\n",
    "            labels.append(label_map[row['label']])\n",
    "    \n",
    "    return np.array(images, dtype=np.float32) / 255.0, np.array(labels)\n",
    "\n",
    "def create_optimized_model(input_shape=(128, 128, 3)):\n",
    "    \"\"\"Optimized architecture\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    XML_PATH = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\analysis\\classificator\\annotations.xml\"\n",
    "    IMG_DIR = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\"\n",
    "    MODEL_PATH = 'bee_classifier_optimized.keras'\n",
    "    \n",
    "    # 1. Data loading\n",
    "    df = parse_cvat_xml(XML_PATH)\n",
    "    print(\"Class distribution:\\n\", df['label'].value_counts())\n",
    "    \n",
    "    # 2. Data preparing\n",
    "    X, y = load_and_preprocess_data(df, IMG_DIR)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # 3. Class balancing\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        'balanced', classes=np.unique(y), y=y)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    print(\"Class weights:\", class_weights)\n",
    "    \n",
    "    # 4. Conservative augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=5,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        zoom_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='constant'\n",
    "    )\n",
    "    \n",
    "    # 5. Creating and training model\n",
    "    model = create_optimized_model()\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5)\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nModel training...\")\n",
    "    history = model.fit(\n",
    "        datagen.flow(X_train, y_train, batch_size=16),\n",
    "        epochs=50,\n",
    "        validation_data=(X_test, y_test),\n",
    "        class_weight=class_weights,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 6. Estimation\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"\\nFinal accuracy: {test_acc:.4f}\")\n",
    "    model.save(MODEL_PATH)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abe35de-d8b6-421c-bdf5-70f4b9429299",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8475df7e-b45c-4824-9338-dcb3d10831a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def predict_single_frame(frame, model, img_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Predicts the class for a single image frame\n",
    "    Parameters:\n",
    "        frame (numpy array): input image in BGR format (as cv2.imread reads)\n",
    "        model: The loaded Keras model\n",
    "        img_size: the size of the image on which the model was trained\n",
    "    Returns:\n",
    "        dict: {'class': 'forward/backward/other', 'probability': float}\n",
    "    \"\"\"\n",
    "    # Image preprocessing\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "    img = cv2.resize(img, img_size)               # Resize\n",
    "    img = img.astype('float32') / 255.0           # Normalization\n",
    "    img = np.expand_dims(img, axis=0)             # Adding batch-shape (1,128,128,3)\n",
    "\n",
    "    # Prediction\n",
    "    predictions = model.predict(img, verbose=0)\n",
    "    class_idx = np.argmax(predictions[0])\n",
    "    class_prob = np.max(predictions[0])\n",
    "\n",
    "    # Mapping indexes to classes\n",
    "    class_names = {0: 'forward', 1: 'backward', 2: 'other'}\n",
    "    \n",
    "    return {\n",
    "        'class': class_names[class_idx],\n",
    "        'probability': float(class_prob)\n",
    "    }\n",
    "\n",
    "MODEL_PATH = 'bee_classifier_new.keras'\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "img_path = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\bee_01867.jpg\"\n",
    "frame = cv2.imread(img_path)\n",
    "\n",
    "prediction = predict_single_frame(frame, model)\n",
    "print(f\"Predicted class: {prediction['class']}, Probability: {prediction['probability']:.4f}\")\n",
    "\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f\"{prediction['class']} ({prediction['probability']:.2%})\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ebccf1-bbc8-4f29-91ce-b70bf3071dde",
   "metadata": {},
   "source": [
    "#### Statistics for test_3_9_10286.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663efbca-5fb7-4d5e-855a-9acde792743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow.keras.models import load_model\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initializing the client for detection\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=\"99oKvIcFbNcIWjEIglpT\"\n",
    ")\n",
    "\n",
    "# Load classification model \n",
    "MODEL_PATH = 'bee_classifier_909.keras'\n",
    "classifier = load_model(MODEL_PATH)\n",
    "\n",
    "# Video parameters\n",
    "video_path = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\gopro\\test_3_9_10286.mp4\"\n",
    "output_dir = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Behavior classification function\n",
    "def classify_bee_behavior(cropped_bee_img, classifier_model, img_size=(128, 128)):\n",
    "    img = cv2.cvtColor(cropped_bee_img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    predictions = classifier_model.predict(img, verbose=0)\n",
    "    class_idx = np.argmax(predictions[0])\n",
    "    class_prob = np.max(predictions[0])\n",
    "    class_names = {0: 'forward', 1: 'backward', 2: 'other'}\n",
    "    \n",
    "    return {\n",
    "        'behavior': class_names[class_idx],\n",
    "        'confidence': float(class_prob)\n",
    "    }\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(f\"Couldn't open the video {video_path}\")\n",
    "\n",
    "# Processing Parameters\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frames_per_minute = int(fps * 60)\n",
    "frame_count = 0\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "# The main processing cycle\n",
    "while frame_count < frames_per_minute:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    current_time = frame_count / fps\n",
    "    \n",
    "    # Bee detection (in a reduced frame for speed)\n",
    "    resized_frame = cv2.resize(frame, (640, 360))\n",
    "    detections = CLIENT.infer(resized_frame, model_id=\"test-tws1v/3\")\n",
    "    \n",
    "    # Scaling the coordinates back to the original size\n",
    "    scale_x = frame.shape[1] / resized_frame.shape[1]\n",
    "    scale_y = frame.shape[0] / resized_frame.shape[0]\n",
    "    \n",
    "    for detection in detections[\"predictions\"]:\n",
    "        if detection[\"class\"].lower() == \"bee\" and detection[\"confidence\"] > 0.5:\n",
    "            # Getting the coordinates of the bounding box\n",
    "            x = int(detection[\"x\"] * scale_x)\n",
    "            y = int(detection[\"y\"] * scale_y)\n",
    "            width = int(detection[\"width\"] * scale_x)\n",
    "            height = int(detection[\"height\"] * scale_y)\n",
    "            \n",
    "            # Correction of coordinates\n",
    "            x1, y1 = max(0, int(x - width/2)), max(0, int(y - height/2))\n",
    "            x2, y2 = min(frame.shape[1], int(x + width/2)), min(frame.shape[0], int(y + height/2))\n",
    "            \n",
    "            # Cutting out an area with a bee\n",
    "            bee_img = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            if bee_img.size == 0:\n",
    "                continue\n",
    "                \n",
    "            # Behavior classification\n",
    "            behavior = classify_bee_behavior(bee_img, classifier)\n",
    "            \n",
    "            # Saving results\n",
    "            results.append({\n",
    "                'frame': frame_count,\n",
    "                'time_seconds': current_time,\n",
    "                'behavior': behavior['behavior'],\n",
    "                'confidence': behavior['confidence'],\n",
    "                'detection_confidence': detection[\"confidence\"],\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "            \n",
    "            # Visualization (once in 30 frames)\n",
    "            if frame_count % 30 == 0:\n",
    "                display_img = cv2.cvtColor(bee_img.copy(), cv2.COLOR_BGR2RGB)\n",
    "                plt.imshow(display_img)\n",
    "                plt.title(f\"Frame {frame_count} ({timedelta(seconds=current_time)})\\n\"\n",
    "                          f\"Behavior: {behavior['behavior']} ({behavior['confidence']:.1%})\\n\"\n",
    "                          f\"Detection: {detection['confidence']:.1%}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            \n",
    "            # Drawing the bounding box and captions\n",
    "            label = f\"{behavior['behavior']} {behavior['confidence']:.1%}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "    \n",
    "    # Progress output\n",
    "    if frame_count % 10 == 0:\n",
    "        print(f\"Обработано {frame_count}/{frames_per_minute} кадров ({current_time:.1f}s)\")\n",
    "    \n",
    "    # Exit with 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Finish\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "processing_time = time.time() - start_time\n",
    "\n",
    "# Saving results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(os.path.join(output_dir, 'behavior_analysis_first_minute.csv'), index=False)\n",
    "\n",
    "print(f\"\\nThe analysis was completed in {processing_time:.1f} seconds\")\n",
    "print(f\"Total bees detected: {len(results)}\")\n",
    "print(f\"Results saved in {os.path.join(output_dir, 'behavior_analysis_first_minute.csv')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c52c2-6517-4fb7-b173-5cce9e33c4cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow.keras.models import load_model\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize detection client\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=\"99oKvIcFbNcIWjEIglpT\"\n",
    ")\n",
    "\n",
    "# Load classification model\n",
    "MODEL_PATH = 'bee_classifier_optimized.keras'\n",
    "classifier = load_model(MODEL_PATH)\n",
    "\n",
    "# Video parameters\n",
    "video_path = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\gopro\\test_3_9_10286.mp4\"\n",
    "output_dir = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Behavior classification function\n",
    "def classify_bee_behavior(cropped_bee_img, classifier_model, img_size=(128, 128)):\n",
    "    img = cv2.cvtColor(cropped_bee_img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    predictions = classifier_model.predict(img, verbose=0)\n",
    "    class_idx = np.argmax(predictions[0])\n",
    "    class_prob = np.max(predictions[0])\n",
    "    class_names = {0: 'forward', 1: 'backward', 2: 'other'}\n",
    "    \n",
    "    return {\n",
    "        'behavior': class_names[class_idx],\n",
    "        'confidence': float(class_prob)\n",
    "    }\n",
    "\n",
    "# Open video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(f\"Failed to open video {video_path}\")\n",
    "\n",
    "# Video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"FPS: {fps}, Total frames: {total_frames}\")\n",
    "\n",
    "# Calculate frame range (20s to 1:20)\n",
    "start_second = 13\n",
    "end_second = 133  # 1 minute 20 seconds\n",
    "start_frame = int(fps * start_second)\n",
    "end_frame = int(fps * end_second)\n",
    "end_frame = min(end_frame, total_frames)  # Don't exceed video length\n",
    "\n",
    "# Set starting position\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Processing parameters\n",
    "frame_count = start_frame\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "# Main processing loop\n",
    "while frame_count <= end_frame:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    current_time = frame_count / fps  # Current time in seconds\n",
    "    \n",
    "    # Detection on resized frame for performance\n",
    "    resized_frame = cv2.resize(frame, (640, 360))\n",
    "    detections = CLIENT.infer(resized_frame, model_id=\"test-tws1v/3\")\n",
    "    \n",
    "    # Scale coordinates back to original size\n",
    "    scale_x = frame.shape[1] / resized_frame.shape[1]\n",
    "    scale_y = frame.shape[0] / resized_frame.shape[0]\n",
    "    \n",
    "    for detection in detections[\"predictions\"]:\n",
    "        if detection[\"class\"].lower() == \"bee\" and detection[\"confidence\"] > 0.5:\n",
    "            # Get bounding box coordinates\n",
    "            x = int(detection[\"x\"] * scale_x)\n",
    "            y = int(detection[\"y\"] * scale_y)\n",
    "            width = int(detection[\"width\"] * scale_x)\n",
    "            height = int(detection[\"height\"] * scale_y)\n",
    "            \n",
    "            # Adjust coordinates\n",
    "            x1 = max(0, int(x - width/2))\n",
    "            y1 = max(0, int(y - height/2))\n",
    "            x2 = min(frame.shape[1], int(x + width/2))\n",
    "            y2 = min(frame.shape[0], int(y + height/2))\n",
    "            \n",
    "            # Extract bee region\n",
    "            bee_img = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            if bee_img.size == 0:\n",
    "                continue\n",
    "                \n",
    "            # Classify behavior\n",
    "            behavior = classify_bee_behavior(bee_img, classifier)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'frame': frame_count,\n",
    "                'time_seconds': current_time,\n",
    "                'behavior': behavior['behavior'],\n",
    "                'confidence': behavior['confidence'],\n",
    "                'detection_confidence': detection[\"confidence\"],\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "            \n",
    "            # Visualization (every 30 frames)\n",
    "            if frame_count % 30 == 0:\n",
    "                display_img = cv2.cvtColor(bee_img.copy(), cv2.COLOR_BGR2RGB)\n",
    "                time_str = str(timedelta(seconds=current_time))[2:7]  # MM:SS format\n",
    "                plt.imshow(display_img)\n",
    "                plt.title(f\"Frame {frame_count} ({time_str})\\n\"\n",
    "                         f\"Behavior: {behavior['behavior']} ({behavior['confidence']:.1%})\\n\"\n",
    "                         f\"Detection: {detection['confidence']:.1%}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            label = f\"{behavior['behavior']} {behavior['confidence']:.1%}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "    \n",
    "    # Print progress\n",
    "    if frame_count % 10 == 0:\n",
    "        time_str = str(timedelta(seconds=current_time))[2:7]\n",
    "        print(f\"Processed frame {frame_count} ({time_str})\")\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "processing_time = time.time() - start_time\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results)\n",
    "output_filename = f'behavior_analysis_{start_second}s_to_{end_second}s.csv'\n",
    "results_df.to_csv(os.path.join(output_dir, output_filename), index=False)\n",
    "\n",
    "print(f\"\\nAnalysis completed in {processing_time:.1f} seconds\")\n",
    "print(f\"Total bees detected: {len(results)}\")\n",
    "print(f\"Results saved to {os.path.join(output_dir, output_filename)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c299b7b-e37b-4749-bd24-4e057cd1954b",
   "metadata": {},
   "source": [
    "### Results visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c255edf-6ef4-4c8c-944f-be20ddc8a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_13s_to_133s.csv\")\n",
    "\n",
    "# Convert time to readable format\n",
    "df['time'] = df['time_seconds'].apply(lambda x: str(timedelta(seconds=x)))[2:7]\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# 1. Behavior distribution over time\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.scatterplot(data=df, x='time_seconds', y='behavior', \n",
    "                hue='behavior', palette={'forward': 'green', 'backward': 'red', 'other': 'blue'},\n",
    "                s=100, alpha=0.7)\n",
    "plt.title('Bee Behavior Over Time', fontsize=16)\n",
    "plt.xlabel('Time (seconds)', fontsize=12)\n",
    "plt.ylabel('Behavior Type', fontsize=12)\n",
    "plt.xticks(ticks=range(0, 61, 5))\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# 2. Cumulative distribution\n",
    "# Verify that data is not empty\n",
    "if not df.empty:\n",
    "    # Group data by time and behavior\n",
    "    behavior_counts = df.groupby(['time_seconds', 'behavior']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Fill missing values with zeros (if any behaviors are missing)\n",
    "    for col in ['forward', 'backward', 'other']:\n",
    "        if col not in behavior_counts.columns:\n",
    "            behavior_counts[col] = 0\n",
    "    \n",
    "    # Sort by time for correct accumulation\n",
    "    behavior_counts = behavior_counts.sort_index()\n",
    "    \n",
    "    # Plot cumulative sum\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    behavior_counts.cumsum().plot(\n",
    "        kind='line',\n",
    "        linewidth=2,\n",
    "        color={'forward': 'green', 'backward': 'red', 'other': 'blue'}\n",
    "    )\n",
    "    \n",
    "    plt.title('Cumulative Behavior Distribution', fontsize=16)\n",
    "    plt.xlabel('Time (seconds)', fontsize=12)\n",
    "    plt.ylabel('Total Detections', fontsize=12)\n",
    "    plt.xticks(range(0, 61, 5))\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend(title='Behavior')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Error: DataFrame is empty. Please check input data.\")\n",
    "\n",
    "# 3. Heatmap visualization (alternative)\n",
    "plt.figure(figsize=(15, 6))\n",
    "heatmap_data = df.groupby(['time', 'behavior']).size().unstack().fillna(0)\n",
    "sns.heatmap(heatmap_data.T, cmap=\"YlGnBu\", annot=True, fmt='.0f', cbar_kws={'label': 'Count'})  # Changed fmt to '.0f'\n",
    "plt.title('Behavior Distribution Over Time', fontsize=16)\n",
    "plt.xlabel('Time (MM:SS)', fontsize=12)\n",
    "plt.ylabel('Behavior Type', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 4. Time interval statistics\n",
    "print(\"\\nStatistics by 10-second intervals:\")\n",
    "df['time_interval'] = (df['time_seconds'] // 10) * 10\n",
    "interval_stats = df.groupby(['time_interval', 'behavior']).size().unstack()\n",
    "print(interval_stats.fillna(0).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7ab294-6217-4e10-bf4d-ae27d29ed2a8",
   "metadata": {},
   "source": [
    "#### Analysis for GX010262 (forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffae539e-4ce7-4356-bcd0-bb9b2d574357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow.keras.models import load_model\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize detection client\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=\"99oKvIcFbNcIWjEIglpT\"\n",
    ")\n",
    "\n",
    "# Load classification model\n",
    "MODEL_PATH = 'bee_classifier_new.keras'\n",
    "classifier = load_model(MODEL_PATH)\n",
    "\n",
    "# Video parameters\n",
    "video_path = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\gopro\\GX010262_rotated.mp4\"\n",
    "output_dir = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Behavior classification function\n",
    "def classify_bee_behavior(cropped_bee_img, classifier_model, img_size=(128, 128)):\n",
    "    img = cv2.cvtColor(cropped_bee_img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    predictions = classifier_model.predict(img, verbose=0)\n",
    "    class_idx = np.argmax(predictions[0])\n",
    "    class_prob = np.max(predictions[0])\n",
    "    class_names = {0: 'forward', 1: 'backward', 2: 'other'}\n",
    "    \n",
    "    return {\n",
    "        'behavior': class_names[class_idx],\n",
    "        'confidence': float(class_prob)\n",
    "    }\n",
    "\n",
    "# Open video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(f\"Failed to open video {video_path}\")\n",
    "\n",
    "# Video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"FPS: {fps}, Total frames: {total_frames}\")\n",
    "\n",
    "# Calculate frame range (20s to 1:20)\n",
    "start_second = 11\n",
    "end_second = 71  # 1 minute 20 seconds\n",
    "start_frame = int(fps * start_second)\n",
    "end_frame = int(fps * end_second)\n",
    "end_frame = min(end_frame, total_frames)  # Don't exceed video length\n",
    "\n",
    "# Set starting position\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Processing parameters\n",
    "frame_count = start_frame\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "# Main processing loop\n",
    "while frame_count <= end_frame:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    current_time = frame_count / fps  # Current time in seconds\n",
    "    \n",
    "    # Detection on resized frame for performance\n",
    "    resized_frame = cv2.resize(frame, (640, 360))\n",
    "    detections = CLIENT.infer(resized_frame, model_id=\"test-tws1v/3\")\n",
    "    \n",
    "    # Scale coordinates back to original size\n",
    "    scale_x = frame.shape[1] / resized_frame.shape[1]\n",
    "    scale_y = frame.shape[0] / resized_frame.shape[0]\n",
    "    \n",
    "    for detection in detections[\"predictions\"]:\n",
    "        if detection[\"class\"].lower() == \"bee\" and detection[\"confidence\"] > 0.5:\n",
    "            # Get bounding box coordinates\n",
    "            x = int(detection[\"x\"] * scale_x)\n",
    "            y = int(detection[\"y\"] * scale_y)\n",
    "            width = int(detection[\"width\"] * scale_x)\n",
    "            height = int(detection[\"height\"] * scale_y)\n",
    "            \n",
    "            # Adjust coordinates\n",
    "            x1 = max(0, int(x - width/2))\n",
    "            y1 = max(0, int(y - height/2))\n",
    "            x2 = min(frame.shape[1], int(x + width/2))\n",
    "            y2 = min(frame.shape[0], int(y + height/2))\n",
    "            \n",
    "            # Extract bee region\n",
    "            bee_img = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            if bee_img.size == 0:\n",
    "                continue\n",
    "                \n",
    "            # Classify behavior\n",
    "            behavior = classify_bee_behavior(bee_img, classifier)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'frame': frame_count,\n",
    "                'time_seconds': current_time,\n",
    "                'behavior': behavior['behavior'],\n",
    "                'confidence': behavior['confidence'],\n",
    "                'detection_confidence': detection[\"confidence\"],\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "            \n",
    "            # Visualization (every 30 frames)\n",
    "            if frame_count % 30 == 0:\n",
    "                display_img = cv2.cvtColor(bee_img.copy(), cv2.COLOR_BGR2RGB)\n",
    "                time_str = str(timedelta(seconds=current_time))[2:7]  # MM:SS format\n",
    "                plt.imshow(display_img)\n",
    "                plt.title(f\"Frame {frame_count} ({time_str})\\n\"\n",
    "                         f\"Behavior: {behavior['behavior']} ({behavior['confidence']:.1%})\\n\"\n",
    "                         f\"Detection: {detection['confidence']:.1%}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            label = f\"{behavior['behavior']} {behavior['confidence']:.1%}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "    \n",
    "    # Print progress\n",
    "    if frame_count % 10 == 0:\n",
    "        time_str = str(timedelta(seconds=current_time))[2:7]\n",
    "        print(f\"Processed frame {frame_count} ({time_str})\")\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "processing_time = time.time() - start_time\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results)\n",
    "output_filename = f'behavior_analysis_{start_second}s_to_{end_second}s.csv'\n",
    "results_df.to_csv(os.path.join(output_dir, output_filename), index=False)\n",
    "\n",
    "print(f\"\\nAnalysis completed in {processing_time:.1f} seconds\")\n",
    "print(f\"Total bees detected: {len(results)}\")\n",
    "print(f\"Results saved to {os.path.join(output_dir, output_filename)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9931204-20c4-4991-afd3-df720e829625",
   "metadata": {},
   "source": [
    "### Visualization for GX010262 (forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800878b9-ae4a-4823-bb38-794ff7a5e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_11s_to_71s.csv\")\n",
    "\n",
    "# Convert time to readable format\n",
    "df['time'] = df['time_seconds'].apply(lambda x: str(timedelta(seconds=x)))[2:7]\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# 1. Behavior distribution over time\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.scatterplot(data=df, x='time_seconds', y='behavior', \n",
    "                hue='behavior', palette={'forward': 'green', 'backward': 'red', 'other': 'blue'},\n",
    "                s=100, alpha=0.7)\n",
    "plt.title('Bee Behavior Over Time', fontsize=16)\n",
    "plt.xlabel('Time (seconds)', fontsize=12)\n",
    "plt.ylabel('Behavior Type', fontsize=12)\n",
    "plt.xticks(ticks=range(0, 61, 5))\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# 2. Cumulative distribution\n",
    "# Verify that data is not empty\n",
    "if not df.empty:\n",
    "    # Group data by time and behavior\n",
    "    behavior_counts = df.groupby(['time_seconds', 'behavior']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Fill missing values with zeros (if any behaviors are missing)\n",
    "    for col in ['forward', 'backward', 'other']:\n",
    "        if col not in behavior_counts.columns:\n",
    "            behavior_counts[col] = 0\n",
    "    \n",
    "    # Sort by time for correct accumulation\n",
    "    behavior_counts = behavior_counts.sort_index()\n",
    "    \n",
    "    # Plot cumulative sum\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    behavior_counts.cumsum().plot(\n",
    "        kind='line',\n",
    "        linewidth=2,\n",
    "        color={'forward': 'green', 'backward': 'red', 'other': 'blue'}\n",
    "    )\n",
    "    \n",
    "    plt.title('Cumulative Behavior Distribution', fontsize=16)\n",
    "    plt.xlabel('Time (seconds)', fontsize=12)\n",
    "    plt.ylabel('Total Detections', fontsize=12)\n",
    "    plt.xticks(range(0, 61, 5))\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend(title='Behavior')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Error: DataFrame is empty. Please check input data.\")\n",
    "\n",
    "# 3. Heatmap visualization (alternative)\n",
    "plt.figure(figsize=(15, 6))\n",
    "heatmap_data = df.groupby(['time', 'behavior']).size().unstack().fillna(0)\n",
    "sns.heatmap(heatmap_data.T, cmap=\"YlGnBu\", annot=True, fmt='.0f', cbar_kws={'label': 'Count'})\n",
    "plt.title('Behavior Distribution Over Time', fontsize=16)\n",
    "plt.xlabel('Time (MM:SS)', fontsize=12)\n",
    "plt.ylabel('Behavior Type', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 4. Time interval statistics\n",
    "print(\"\\nStatistics by 10-second intervals:\")\n",
    "df['time_interval'] = (df['time_seconds'] // 10) * 10\n",
    "interval_stats = df.groupby(['time_interval', 'behavior']).size().unstack()\n",
    "print(interval_stats.fillna(0).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d445fc0a-1268-4679-8444-54c1eaee8c13",
   "metadata": {},
   "source": [
    "#### Analysis for GX010262 (backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d8d2e-7131-4bab-968f-9b6e4c37f81a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow.keras.models import load_model\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize detection client\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=\"99oKvIcFbNcIWjEIglpT\"\n",
    ")\n",
    "\n",
    "# Load classification model\n",
    "MODEL_PATH = 'bee_classifier_909.keras'\n",
    "classifier = load_model(MODEL_PATH)\n",
    "\n",
    "# Video parameters\n",
    "video_path = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\gopro\\GX010262_rotated.mp4\"\n",
    "output_dir = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Behavior classification function\n",
    "def classify_bee_behavior(cropped_bee_img, classifier_model, img_size=(128, 128)):\n",
    "    img = cv2.cvtColor(cropped_bee_img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    predictions = classifier_model.predict(img, verbose=0)\n",
    "    class_idx = np.argmax(predictions[0])\n",
    "    class_prob = np.max(predictions[0])\n",
    "    class_names = {0: 'forward', 1: 'backward', 2: 'other'}\n",
    "    \n",
    "    return {\n",
    "        'behavior': class_names[class_idx],\n",
    "        'confidence': float(class_prob)\n",
    "    }\n",
    "\n",
    "# Open video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(f\"Failed to open video {video_path}\")\n",
    "\n",
    "# Video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"FPS: {fps}, Total frames: {total_frames}\")\n",
    "\n",
    "# Calculate frame range (20s to 1:20)\n",
    "start_second = 153\n",
    "end_second = 217  # 1 minute 20 seconds\n",
    "start_frame = int(fps * start_second)\n",
    "end_frame = int(fps * end_second)\n",
    "end_frame = min(end_frame, total_frames)  # Don't exceed video length\n",
    "\n",
    "# Set starting position\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Processing parameters\n",
    "frame_count = start_frame\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "# Main processing loop\n",
    "while frame_count <= end_frame:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    current_time = frame_count / fps  # Current time in seconds\n",
    "    \n",
    "    # Detection on resized frame for performance\n",
    "    resized_frame = cv2.resize(frame, (640, 360))\n",
    "    detections = CLIENT.infer(resized_frame, model_id=\"test-tws1v/3\")\n",
    "    \n",
    "    # Scale coordinates back to original size\n",
    "    scale_x = frame.shape[1] / resized_frame.shape[1]\n",
    "    scale_y = frame.shape[0] / resized_frame.shape[0]\n",
    "    \n",
    "    for detection in detections[\"predictions\"]:\n",
    "        if detection[\"class\"].lower() == \"bee\" and detection[\"confidence\"] > 0.5:\n",
    "            # Get bounding box coordinates\n",
    "            x = int(detection[\"x\"] * scale_x)\n",
    "            y = int(detection[\"y\"] * scale_y)\n",
    "            width = int(detection[\"width\"] * scale_x)\n",
    "            height = int(detection[\"height\"] * scale_y)\n",
    "            \n",
    "            # Adjust coordinates\n",
    "            x1 = max(0, int(x - width/2))\n",
    "            y1 = max(0, int(y - height/2))\n",
    "            x2 = min(frame.shape[1], int(x + width/2))\n",
    "            y2 = min(frame.shape[0], int(y + height/2))\n",
    "            \n",
    "            # Extract bee region\n",
    "            bee_img = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            if bee_img.size == 0:\n",
    "                continue\n",
    "                \n",
    "            # Classify behavior\n",
    "            behavior = classify_bee_behavior(bee_img, classifier)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'frame': frame_count,\n",
    "                'time_seconds': current_time,\n",
    "                'behavior': behavior['behavior'],\n",
    "                'confidence': behavior['confidence'],\n",
    "                'detection_confidence': detection[\"confidence\"],\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "            \n",
    "            # Visualization (every 30 frames)\n",
    "            if frame_count % 30 == 0:\n",
    "                display_img = cv2.cvtColor(bee_img.copy(), cv2.COLOR_BGR2RGB)\n",
    "                time_str = str(timedelta(seconds=current_time))[2:7]  # MM:SS format\n",
    "                plt.imshow(display_img)\n",
    "                plt.title(f\"Frame {frame_count} ({time_str})\\n\"\n",
    "                         f\"Behavior: {behavior['behavior']} ({behavior['confidence']:.1%})\\n\"\n",
    "                         f\"Detection: {detection['confidence']:.1%}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            label = f\"{behavior['behavior']} {behavior['confidence']:.1%}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "    \n",
    "    # Print progress\n",
    "    if frame_count % 10 == 0:\n",
    "        time_str = str(timedelta(seconds=current_time))[2:7]\n",
    "        print(f\"Processed frame {frame_count} ({time_str})\")\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "processing_time = time.time() - start_time\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results)\n",
    "output_filename = f'behavior_analysis_{start_second}s_to_{end_second}s.csv'\n",
    "results_df.to_csv(os.path.join(output_dir, output_filename), index=False)\n",
    "\n",
    "print(f\"\\nAnalysis completed in {processing_time:.1f} seconds\")\n",
    "print(f\"Total bees detected: {len(results)}\")\n",
    "print(f\"Results saved to {os.path.join(output_dir, output_filename)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6bc402-dcaf-46d3-bf63-a81abd5fc392",
   "metadata": {},
   "source": [
    "### Visualization for GX010262 (backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5029980c-a1f3-40d0-94ce-d6fe94bd87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_153s_to_217s.csv\")\n",
    "\n",
    "# Convert time to readable format\n",
    "df['time'] = df['time_seconds'].apply(lambda x: str(timedelta(seconds=x)))[2:7]\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# 1. Behavior distribution over time\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.scatterplot(data=df, x='time_seconds', y='behavior', \n",
    "                hue='behavior', palette={'forward': 'green', 'backward': 'red', 'other': 'blue'},\n",
    "                s=100, alpha=0.7)\n",
    "plt.title('Bee Behavior Over Time', fontsize=16)\n",
    "plt.xlabel('Time (seconds)', fontsize=12)\n",
    "plt.ylabel('Behavior Type', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(ticks=range(150, 220, 10))  # Adjust for your range\n",
    "plt.xlim(150, 220)  # Set X-axis boundaries\n",
    "\n",
    "\n",
    "# 2. Cumulative distribution\n",
    "# Verify that data is not empty\n",
    "if not df.empty:\n",
    "    # Group data by time and behavior\n",
    "    behavior_counts = df.groupby(['time_seconds', 'behavior']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Fill missing values with zeros (if any behaviors are missing)\n",
    "    for col in ['forward', 'backward', 'other']:\n",
    "        if col not in behavior_counts.columns:\n",
    "            behavior_counts[col] = 0\n",
    "    \n",
    "    # Sort by time for correct accumulation\n",
    "    behavior_counts = behavior_counts.sort_index()\n",
    "    \n",
    "    # Plot cumulative sum\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    behavior_counts.cumsum().plot(\n",
    "        kind='line',\n",
    "        linewidth=2,\n",
    "        color={'forward': 'green', 'backward': 'red', 'other': 'blue'}\n",
    "    )\n",
    "    \n",
    "    plt.title('Cumulative Behavior Distribution', fontsize=16)\n",
    "    plt.xlabel('Time (seconds)', fontsize=12)\n",
    "    plt.ylabel('Total Detections', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend(title='Behavior')\n",
    "    plt.xticks(ticks=range(150, 220, 10))  # Adjust for your range\n",
    "    plt.xlim(150, 220)  # Set X-axis boundaries\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Error: DataFrame is empty. Please check input data.\")\n",
    "\n",
    "# 3. Heatmap visualization (alternative)\n",
    "plt.figure(figsize=(15, 6))\n",
    "heatmap_data = df.groupby(['time', 'behavior']).size().unstack().fillna(0)\n",
    "sns.heatmap(heatmap_data.T, cmap=\"YlGnBu\", annot=True, fmt='.0f', cbar_kws={'label': 'Count'})\n",
    "plt.title('Behavior Distribution Over Time', fontsize=16)\n",
    "plt.xlabel('Time (MM:SS)', fontsize=12)\n",
    "plt.ylabel('Behavior Type', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 4. Time interval statistics\n",
    "print(\"\\nStatistics by 10-second intervals:\")\n",
    "df['time_interval'] = (df['time_seconds'] // 10) * 10\n",
    "interval_stats = df.groupby(['time_interval', 'behavior']).size().unstack()\n",
    "print(interval_stats.fillna(0).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f9f5e-40e8-422e-a432-2b81d5b355dd",
   "metadata": {},
   "source": [
    "test_3_9_10286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea3dc99-0f87-40f1-a928-ce1b3a8164fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow.keras.models import load_model\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize detection client\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=\"99oKvIcFbNcIWjEIglpT\"\n",
    ")\n",
    "\n",
    "# Load classification model\n",
    "MODEL_PATH = 'bee_classifier_909.keras'\n",
    "classifier = load_model(MODEL_PATH)\n",
    "\n",
    "# Video parameters\n",
    "video_path = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\gopro\\test_3_9_10286.mp4\"\n",
    "output_dir = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Behavior classification function\n",
    "def classify_bee_behavior(cropped_bee_img, classifier_model, img_size=(128, 128)):\n",
    "    img = cv2.cvtColor(cropped_bee_img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    predictions = classifier_model.predict(img, verbose=0)\n",
    "    class_idx = np.argmax(predictions[0])\n",
    "    class_prob = np.max(predictions[0])\n",
    "    class_names = {0: 'forward', 1: 'backward', 2: 'other'}\n",
    "    \n",
    "    return {\n",
    "        'behavior': class_names[class_idx],\n",
    "        'confidence': float(class_prob)\n",
    "    }\n",
    "\n",
    "# Open video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(f\"Failed to open video {video_path}\")\n",
    "\n",
    "# Video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"FPS: {fps}, Total frames: {total_frames}\")\n",
    "\n",
    "# Calculate frame range (20s to 1:20)\n",
    "start_second = 13\n",
    "end_second = 73  # 1 minute 20 seconds\n",
    "start_frame = int(fps * start_second)\n",
    "end_frame = int(fps * end_second)\n",
    "end_frame = min(end_frame, total_frames)  # Don't exceed video length\n",
    "\n",
    "# Set starting position\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Processing parameters\n",
    "frame_count = start_frame\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "# Main processing loop\n",
    "while frame_count <= end_frame:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    current_time = frame_count / fps  # Current time in seconds\n",
    "    \n",
    "    # Detection on resized frame for performance\n",
    "    resized_frame = cv2.resize(frame, (640, 360))\n",
    "    detections = CLIENT.infer(resized_frame, model_id=\"test-tws1v/3\")\n",
    "    \n",
    "    # Scale coordinates back to original size\n",
    "    scale_x = frame.shape[1] / resized_frame.shape[1]\n",
    "    scale_y = frame.shape[0] / resized_frame.shape[0]\n",
    "    \n",
    "    for detection in detections[\"predictions\"]:\n",
    "        if detection[\"class\"].lower() == \"bee\" and detection[\"confidence\"] > 0.5:\n",
    "            # Get bounding box coordinates\n",
    "            x = int(detection[\"x\"] * scale_x)\n",
    "            y = int(detection[\"y\"] * scale_y)\n",
    "            width = int(detection[\"width\"] * scale_x)\n",
    "            height = int(detection[\"height\"] * scale_y)\n",
    "            \n",
    "            # Adjust coordinates\n",
    "            x1 = max(0, int(x - width/2))\n",
    "            y1 = max(0, int(y - height/2))\n",
    "            x2 = min(frame.shape[1], int(x + width/2))\n",
    "            y2 = min(frame.shape[0], int(y + height/2))\n",
    "            \n",
    "            # Extract bee region\n",
    "            bee_img = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            if bee_img.size == 0:\n",
    "                continue\n",
    "                \n",
    "            # Classify behavior\n",
    "            behavior = classify_bee_behavior(bee_img, classifier)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'frame': frame_count,\n",
    "                'time_seconds': current_time,\n",
    "                'behavior': behavior['behavior'],\n",
    "                'confidence': behavior['confidence'],\n",
    "                'detection_confidence': detection[\"confidence\"],\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "            \n",
    "            # Visualization (every 30 frames)\n",
    "            if frame_count % 30 == 0:\n",
    "                display_img = cv2.cvtColor(bee_img.copy(), cv2.COLOR_BGR2RGB)\n",
    "                time_str = str(timedelta(seconds=current_time))[2:7]  # MM:SS format\n",
    "                plt.imshow(display_img)\n",
    "                plt.title(f\"Frame {frame_count} ({time_str})\\n\"\n",
    "                         f\"Behavior: {behavior['behavior']} ({behavior['confidence']:.1%})\\n\"\n",
    "                         f\"Detection: {detection['confidence']:.1%}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            label = f\"{behavior['behavior']} {behavior['confidence']:.1%}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "    \n",
    "    # Print progress\n",
    "    if frame_count % 10 == 0:\n",
    "        time_str = str(timedelta(seconds=current_time))[2:7]\n",
    "        print(f\"Processed frame {frame_count} ({time_str})\")\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "processing_time = time.time() - start_time\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results)\n",
    "output_filename = f'behavior_analysis_test_3_9_10286_forward.csv'\n",
    "results_df.to_csv(os.path.join(output_dir, output_filename), index=False)\n",
    "\n",
    "print(f\"\\nAnalysis completed in {processing_time:.1f} seconds\")\n",
    "print(f\"Total bees detected: {len(results)}\")\n",
    "print(f\"Results saved to {os.path.join(output_dir, output_filename)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c58abe-34bc-42a1-9769-ede18b7d10dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_test_3_9_10286_forward.csv\")\n",
    "\n",
    "# Convert time to readable format\n",
    "df['time'] = df['time_seconds'].apply(lambda x: str(timedelta(seconds=x)))[2:7]\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# 1. Behavior distribution over time\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.scatterplot(data=df, x='time_seconds', y='behavior', \n",
    "                hue='behavior', palette={'forward': 'green', 'backward': 'red', 'other': 'blue'},\n",
    "                s=100, alpha=0.7)\n",
    "plt.title('Bee Behavior Over Time', fontsize=16)\n",
    "plt.xlabel('Time (seconds)', fontsize=12)\n",
    "plt.ylabel('Behavior Type', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(ticks=range(13, 73, 10))  # Adjust for your time range\n",
    "plt.xlim(13, 73)  # Set X-axis boundaries\n",
    "\n",
    "\n",
    "# 2. Cumulative distribution\n",
    "# Verify that data is not empty\n",
    "if not df.empty:\n",
    "    # Group data by time and behavior\n",
    "    behavior_counts = df.groupby(['time_seconds', 'behavior']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Fill missing values with zeros (if any behaviors are missing)\n",
    "    for col in ['forward', 'backward', 'other']:\n",
    "        if col not in behavior_counts.columns:\n",
    "            behavior_counts[col] = 0\n",
    "    \n",
    "    # Sort by time for correct accumulation\n",
    "    behavior_counts = behavior_counts.sort_index()\n",
    "    \n",
    "    # Plot cumulative sum\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    behavior_counts.cumsum().plot(\n",
    "        kind='line',\n",
    "        linewidth=2,\n",
    "        color={'forward': 'green', 'backward': 'red', 'other': 'blue'}\n",
    "    )\n",
    "    \n",
    "    plt.title('Cumulative Behavior Distribution', fontsize=16)\n",
    "    plt.xlabel('Time (seconds)', fontsize=12)\n",
    "    plt.ylabel('Total Detections', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend(title='Behavior')\n",
    "    plt.xticks(ticks=range(13, 73, 10))  # Adjust for your time range\n",
    "    plt.xlim(13, 73)  # Set X-axis boundaries\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Error: DataFrame is empty. Please check input data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d299fc-1b80-48c5-8c03-3a1a29f2bab6",
   "metadata": {},
   "source": [
    "#### Backward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e4315-1303-4eff-bb0b-a3ff0a6449ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow.keras.models import load_model\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize detection client\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=\"99oKvIcFbNcIWjEIglpT\"\n",
    ")\n",
    "\n",
    "# Load classification model\n",
    "MODEL_PATH = 'bee_classifier_909.keras'\n",
    "classifier = load_model(MODEL_PATH)\n",
    "\n",
    "# Video parameters\n",
    "video_path = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\gopro\\test_3_9_10286.mp4\"\n",
    "output_dir = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Behavior classification function\n",
    "def classify_bee_behavior(cropped_bee_img, classifier_model, img_size=(128, 128)):\n",
    "    img = cv2.cvtColor(cropped_bee_img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    predictions = classifier_model.predict(img, verbose=0)\n",
    "    class_idx = np.argmax(predictions[0])\n",
    "    class_prob = np.max(predictions[0])\n",
    "    class_names = {0: 'forward', 1: 'backward', 2: 'other'}\n",
    "    \n",
    "    return {\n",
    "        'behavior': class_names[class_idx],\n",
    "        'confidence': float(class_prob)\n",
    "    }\n",
    "\n",
    "# Open video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(f\"Failed to open video {video_path}\")\n",
    "\n",
    "# Video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"FPS: {fps}, Total frames: {total_frames}\")\n",
    "\n",
    "# Calculate frame range (20s to 1:20)\n",
    "start_second = 301\n",
    "end_second = 361  # 1 minute 20 seconds\n",
    "start_frame = int(fps * start_second)\n",
    "end_frame = int(fps * end_second)\n",
    "end_frame = min(end_frame, total_frames)  # Don't exceed video length\n",
    "\n",
    "# Set starting position\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Processing parameters\n",
    "frame_count = start_frame\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "# Main processing loop\n",
    "while frame_count <= end_frame:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    current_time = frame_count / fps  # Current time in seconds\n",
    "    \n",
    "    # Detection on resized frame for performance\n",
    "    resized_frame = cv2.resize(frame, (640, 360))\n",
    "    detections = CLIENT.infer(resized_frame, model_id=\"test-tws1v/3\")\n",
    "    \n",
    "    # Scale coordinates back to original size\n",
    "    scale_x = frame.shape[1] / resized_frame.shape[1]\n",
    "    scale_y = frame.shape[0] / resized_frame.shape[0]\n",
    "    \n",
    "    for detection in detections[\"predictions\"]:\n",
    "        if detection[\"class\"].lower() == \"bee\" and detection[\"confidence\"] > 0.5:\n",
    "            # Get bounding box coordinates\n",
    "            x = int(detection[\"x\"] * scale_x)\n",
    "            y = int(detection[\"y\"] * scale_y)\n",
    "            width = int(detection[\"width\"] * scale_x)\n",
    "            height = int(detection[\"height\"] * scale_y)\n",
    "            \n",
    "            # Adjust coordinates\n",
    "            x1 = max(0, int(x - width/2))\n",
    "            y1 = max(0, int(y - height/2))\n",
    "            x2 = min(frame.shape[1], int(x + width/2))\n",
    "            y2 = min(frame.shape[0], int(y + height/2))\n",
    "            \n",
    "            # Extract bee region\n",
    "            bee_img = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            if bee_img.size == 0:\n",
    "                continue\n",
    "                \n",
    "            # Classify behavior\n",
    "            behavior = classify_bee_behavior(bee_img, classifier)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'frame': frame_count,\n",
    "                'time_seconds': current_time,\n",
    "                'behavior': behavior['behavior'],\n",
    "                'confidence': behavior['confidence'],\n",
    "                'detection_confidence': detection[\"confidence\"],\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "            \n",
    "            # Visualization (every 30 frames)\n",
    "            if frame_count % 30 == 0:\n",
    "                display_img = cv2.cvtColor(bee_img.copy(), cv2.COLOR_BGR2RGB)\n",
    "                time_str = str(timedelta(seconds=current_time))[2:7]  # MM:SS format\n",
    "                plt.imshow(display_img)\n",
    "                plt.title(f\"Frame {frame_count} ({time_str})\\n\"\n",
    "                         f\"Behavior: {behavior['behavior']} ({behavior['confidence']:.1%})\\n\"\n",
    "                         f\"Detection: {detection['confidence']:.1%}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            label = f\"{behavior['behavior']} {behavior['confidence']:.1%}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "    \n",
    "    # Print progress\n",
    "    if frame_count % 10 == 0:\n",
    "        time_str = str(timedelta(seconds=current_time))[2:7]\n",
    "        print(f\"Processed frame {frame_count} ({time_str})\")\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "processing_time = time.time() - start_time\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results)\n",
    "output_filename = f'behavior_analysis_test_3_9_10286_backward.csv'\n",
    "results_df.to_csv(os.path.join(output_dir, output_filename), index=False)\n",
    "\n",
    "print(f\"\\nAnalysis completed in {processing_time:.1f} seconds\")\n",
    "print(f\"Total bees detected: {len(results)}\")\n",
    "print(f\"Results saved to {os.path.join(output_dir, output_filename)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d675a636-caba-4a9c-9936-27d731f4d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_test_3_9_10286_backward.csv\")\n",
    "\n",
    "# Convert time to readable format\n",
    "df['time'] = df['time_seconds'].apply(lambda x: str(timedelta(seconds=x)))[2:7]\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# 1. Behavior distribution over time\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.scatterplot(data=df, x='time_seconds', y='behavior', \n",
    "                hue='behavior', palette={'forward': 'green', 'backward': 'red', 'other': 'blue'},\n",
    "                s=100, alpha=0.7)\n",
    "plt.title('Bee Behavior Over Time', fontsize=16)\n",
    "plt.xlabel('Time (seconds)', fontsize=12)\n",
    "plt.ylabel('Behavior Type', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(ticks=range(301, 361, 10))  # Adjust for your time range\n",
    "plt.xlim(301, 361)  # Set X-axis boundaries\n",
    "\n",
    "\n",
    "# 2. Cumulative distribution\n",
    "# Verify that data is not empty\n",
    "if not df.empty:\n",
    "    # Group data by time and behavior\n",
    "    behavior_counts = df.groupby(['time_seconds', 'behavior']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Fill missing values with zeros (if any behaviors are missing)\n",
    "    for col in ['forward', 'backward', 'other']:\n",
    "        if col not in behavior_counts.columns:\n",
    "            behavior_counts[col] = 0\n",
    "    \n",
    "    # Sort by time for correct accumulation\n",
    "    behavior_counts = behavior_counts.sort_index()\n",
    "    \n",
    "    # Plot cumulative sum\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    behavior_counts.cumsum().plot(\n",
    "        kind='line',\n",
    "        linewidth=2,\n",
    "        color={'forward': 'green', 'backward': 'red', 'other': 'blue'}\n",
    "    )\n",
    "    \n",
    "    plt.title('Cumulative Behavior Distribution', fontsize=16)\n",
    "    plt.xlabel('Time (seconds)', fontsize=12)\n",
    "    plt.ylabel('Total Detections', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend(title='Behavior')\n",
    "    plt.xticks(ticks=range(301, 361, 10))  # Adjust for your time range\n",
    "    plt.xlim(301, 361)  # Set X-axis boundaries\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Error: DataFrame is empty. Please check input data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b86d5-7503-4a71-aeba-ba321164e391",
   "metadata": {},
   "source": [
    "#### GX010297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d154b-73d0-4bb8-a70c-3d7a964bdfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow.keras.models import load_model\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize detection client\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=\"99oKvIcFbNcIWjEIglpT\"\n",
    ")\n",
    "\n",
    "# Load classification model\n",
    "MODEL_PATH = 'bee_classifier_909.keras'\n",
    "classifier = load_model(MODEL_PATH)\n",
    "\n",
    "# Video parameters\n",
    "video_path = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\gopro\\GX010297.mp4\"\n",
    "output_dir = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Behavior classification function\n",
    "def classify_bee_behavior(cropped_bee_img, classifier_model, img_size=(128, 128)):\n",
    "    img = cv2.cvtColor(cropped_bee_img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    predictions = classifier_model.predict(img, verbose=0)\n",
    "    class_idx = np.argmax(predictions[0])\n",
    "    class_prob = np.max(predictions[0])\n",
    "    class_names = {0: 'forward', 1: 'backward', 2: 'other'}\n",
    "    \n",
    "    return {\n",
    "        'behavior': class_names[class_idx],\n",
    "        'confidence': float(class_prob)\n",
    "    }\n",
    "\n",
    "# Open video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(f\"Failed to open video {video_path}\")\n",
    "\n",
    "# Video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"FPS: {fps}, Total frames: {total_frames}\")\n",
    "\n",
    "# Calculate frame range (20s to 1:20)\n",
    "start_second = 15\n",
    "end_second = 75  # 1 minute 20 seconds\n",
    "start_frame = int(fps * start_second)\n",
    "end_frame = int(fps * end_second)\n",
    "end_frame = min(end_frame, total_frames)  # Don't exceed video length\n",
    "\n",
    "# Set starting position\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Processing parameters\n",
    "frame_count = start_frame\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "# Main processing loop\n",
    "while frame_count <= end_frame:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    current_time = frame_count / fps  # Current time in seconds\n",
    "    \n",
    "    # Detection on resized frame for performance\n",
    "    resized_frame = cv2.resize(frame, (640, 360))\n",
    "    detections = CLIENT.infer(resized_frame, model_id=\"test-tws1v/3\")\n",
    "    \n",
    "    # Scale coordinates back to original size\n",
    "    scale_x = frame.shape[1] / resized_frame.shape[1]\n",
    "    scale_y = frame.shape[0] / resized_frame.shape[0]\n",
    "    \n",
    "    for detection in detections[\"predictions\"]:\n",
    "        if detection[\"class\"].lower() == \"bee\" and detection[\"confidence\"] > 0.5:\n",
    "            # Get bounding box coordinates\n",
    "            x = int(detection[\"x\"] * scale_x)\n",
    "            y = int(detection[\"y\"] * scale_y)\n",
    "            width = int(detection[\"width\"] * scale_x)\n",
    "            height = int(detection[\"height\"] * scale_y)\n",
    "            \n",
    "            # Adjust coordinates\n",
    "            x1 = max(0, int(x - width/2))\n",
    "            y1 = max(0, int(y - height/2))\n",
    "            x2 = min(frame.shape[1], int(x + width/2))\n",
    "            y2 = min(frame.shape[0], int(y + height/2))\n",
    "            \n",
    "            # Extract bee region\n",
    "            bee_img = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            if bee_img.size == 0:\n",
    "                continue\n",
    "                \n",
    "            # Classify behavior\n",
    "            behavior = classify_bee_behavior(bee_img, classifier)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'frame': frame_count,\n",
    "                'time_seconds': current_time,\n",
    "                'behavior': behavior['behavior'],\n",
    "                'confidence': behavior['confidence'],\n",
    "                'detection_confidence': detection[\"confidence\"],\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "            \n",
    "            # Visualization (every 30 frames)\n",
    "            if frame_count % 30 == 0:\n",
    "                display_img = cv2.cvtColor(bee_img.copy(), cv2.COLOR_BGR2RGB)\n",
    "                time_str = str(timedelta(seconds=current_time))[2:7]  # MM:SS format\n",
    "                plt.imshow(display_img)\n",
    "                plt.title(f\"Frame {frame_count} ({time_str})\\n\"\n",
    "                         f\"Behavior: {behavior['behavior']} ({behavior['confidence']:.1%})\\n\"\n",
    "                         f\"Detection: {detection['confidence']:.1%}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            label = f\"{behavior['behavior']} {behavior['confidence']:.1%}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "    \n",
    "    # Print progress\n",
    "    if frame_count % 10 == 0:\n",
    "        time_str = str(timedelta(seconds=current_time))[2:7]\n",
    "        print(f\"Processed frame {frame_count} ({time_str})\")\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "processing_time = time.time() - start_time\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results)\n",
    "output_filename = f'behavior_analysis_GX010297_forward.csv'\n",
    "results_df.to_csv(os.path.join(output_dir, output_filename), index=False)\n",
    "\n",
    "print(f\"\\nAnalysis completed in {processing_time:.1f} seconds\")\n",
    "print(f\"Total bees detected: {len(results)}\")\n",
    "print(f\"Results saved to {os.path.join(output_dir, output_filename)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218db536-fa94-4cbe-b38c-447ca263c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_GX010297_forward.csv\")\n",
    "\n",
    "# Convert time to readable format\n",
    "df['time'] = df['time_seconds'].apply(lambda x: str(timedelta(seconds=x)))[2:7]\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# 1. Behavior distribution over time\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.scatterplot(data=df, x='time_seconds', y='behavior', \n",
    "                hue='behavior', palette={'forward': 'green', 'backward': 'red', 'other': 'blue'},\n",
    "                s=100, alpha=0.7)\n",
    "plt.title('Bee Behavior Over Time', fontsize=16)\n",
    "plt.xlabel('Time (seconds)', fontsize=12)\n",
    "plt.ylabel('Behavior Type', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(ticks=range(15, 75, 10))  # Adjust for your time range\n",
    "plt.xlim(15, 75)  # Set X-axis boundaries\n",
    "\n",
    "\n",
    "# 2. Cumulative distribution\n",
    "# Verify that data is not empty\n",
    "if not df.empty:\n",
    "    # Group data by time and behavior\n",
    "    behavior_counts = df.groupby(['time_seconds', 'behavior']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Fill missing values with zeros (if any behaviors are missing)\n",
    "    for col in ['forward', 'backward', 'other']:\n",
    "        if col not in behavior_counts.columns:\n",
    "            behavior_counts[col] = 0\n",
    "    \n",
    "    # Sort by time for correct accumulation\n",
    "    behavior_counts = behavior_counts.sort_index()\n",
    "    \n",
    "    # Plot cumulative sum\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    behavior_counts.cumsum().plot(\n",
    "        kind='line',\n",
    "        linewidth=2,\n",
    "        color={'forward': 'green', 'backward': 'red', 'other': 'blue'}\n",
    "    )\n",
    "    \n",
    "    plt.title('Cumulative Behavior Distribution', fontsize=16)\n",
    "    plt.xlabel('Time (seconds)', fontsize=12)\n",
    "    plt.ylabel('Total Detections', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend(title='Behavior')\n",
    "    plt.xticks(ticks=range(15, 75, 10))  # Adjust for your time range\n",
    "    plt.xlim(15, 75)  # Set X-axis boundaries\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Error: DataFrame is empty. Please check input data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a07f43-82b0-477b-b1ac-4f16c2bc3ae8",
   "metadata": {},
   "source": [
    "#### Backward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5602c29-0516-46e3-8e77-fcef7b85cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow.keras.models import load_model\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize detection client\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=\"99oKvIcFbNcIWjEIglpT\"\n",
    ")\n",
    "\n",
    "# Load classification model\n",
    "MODEL_PATH = 'bee_classifier_909.keras'\n",
    "classifier = load_model(MODEL_PATH)\n",
    "\n",
    "# Video parameters\n",
    "video_path = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\gopro\\GX010297.mp4\"\n",
    "output_dir = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Behavior classification function\n",
    "def classify_bee_behavior(cropped_bee_img, classifier_model, img_size=(128, 128)):\n",
    "    img = cv2.cvtColor(cropped_bee_img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    predictions = classifier_model.predict(img, verbose=0)\n",
    "    class_idx = np.argmax(predictions[0])\n",
    "    class_prob = np.max(predictions[0])\n",
    "    class_names = {0: 'forward', 1: 'backward', 2: 'other'}\n",
    "    \n",
    "    return {\n",
    "        'behavior': class_names[class_idx],\n",
    "        'confidence': float(class_prob)\n",
    "    }\n",
    "\n",
    "# Open video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(f\"Failed to open video {video_path}\")\n",
    "\n",
    "# Video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"FPS: {fps}, Total frames: {total_frames}\")\n",
    "\n",
    "# Calculate frame range (20s to 1:20)\n",
    "start_second = 240\n",
    "end_second = 300  # 1 minute 20 seconds\n",
    "start_frame = int(fps * start_second)\n",
    "end_frame = int(fps * end_second)\n",
    "end_frame = min(end_frame, total_frames)  # Don't exceed video length\n",
    "\n",
    "# Set starting position\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Processing parameters\n",
    "frame_count = start_frame\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "# Main processing loop\n",
    "while frame_count <= end_frame:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    current_time = frame_count / fps  # Current time in seconds\n",
    "    \n",
    "    # Detection on resized frame for performance\n",
    "    resized_frame = cv2.resize(frame, (640, 360))\n",
    "    detections = CLIENT.infer(resized_frame, model_id=\"test-tws1v/3\")\n",
    "    \n",
    "    # Scale coordinates back to original size\n",
    "    scale_x = frame.shape[1] / resized_frame.shape[1]\n",
    "    scale_y = frame.shape[0] / resized_frame.shape[0]\n",
    "    \n",
    "    for detection in detections[\"predictions\"]:\n",
    "        if detection[\"class\"].lower() == \"bee\" and detection[\"confidence\"] > 0.5:\n",
    "            # Get bounding box coordinates\n",
    "            x = int(detection[\"x\"] * scale_x)\n",
    "            y = int(detection[\"y\"] * scale_y)\n",
    "            width = int(detection[\"width\"] * scale_x)\n",
    "            height = int(detection[\"height\"] * scale_y)\n",
    "            \n",
    "            # Adjust coordinates\n",
    "            x1 = max(0, int(x - width/2))\n",
    "            y1 = max(0, int(y - height/2))\n",
    "            x2 = min(frame.shape[1], int(x + width/2))\n",
    "            y2 = min(frame.shape[0], int(y + height/2))\n",
    "            \n",
    "            # Extract bee region\n",
    "            bee_img = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            if bee_img.size == 0:\n",
    "                continue\n",
    "                \n",
    "            # Classify behavior\n",
    "            behavior = classify_bee_behavior(bee_img, classifier)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'frame': frame_count,\n",
    "                'time_seconds': current_time,\n",
    "                'behavior': behavior['behavior'],\n",
    "                'confidence': behavior['confidence'],\n",
    "                'detection_confidence': detection[\"confidence\"],\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "            \n",
    "            # Visualization (every 30 frames)\n",
    "            if frame_count % 30 == 0:\n",
    "                display_img = cv2.cvtColor(bee_img.copy(), cv2.COLOR_BGR2RGB)\n",
    "                time_str = str(timedelta(seconds=current_time))[2:7]  # MM:SS format\n",
    "                plt.imshow(display_img)\n",
    "                plt.title(f\"Frame {frame_count} ({time_str})\\n\"\n",
    "                         f\"Behavior: {behavior['behavior']} ({behavior['confidence']:.1%})\\n\"\n",
    "                         f\"Detection: {detection['confidence']:.1%}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            label = f\"{behavior['behavior']} {behavior['confidence']:.1%}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "    \n",
    "    # Print progress\n",
    "    if frame_count % 10 == 0:\n",
    "        time_str = str(timedelta(seconds=current_time))[2:7]\n",
    "        print(f\"Processed frame {frame_count} ({time_str})\")\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "processing_time = time.time() - start_time\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results)\n",
    "output_filename = f'behavior_analysis_GX010297_backward.csv'\n",
    "results_df.to_csv(os.path.join(output_dir, output_filename), index=False)\n",
    "\n",
    "print(f\"\\nAnalysis completed in {processing_time:.1f} seconds\")\n",
    "print(f\"Total bees detected: {len(results)}\")\n",
    "print(f\"Results saved to {os.path.join(output_dir, output_filename)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03953f55-621e-4994-820c-b5c46865683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_GX010297_backward.csv\")\n",
    "\n",
    "# Convert time to readable format\n",
    "df['time'] = df['time_seconds'].apply(lambda x: str(timedelta(seconds=x)))[2:7]\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# 1. Behavior distribution over time\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.scatterplot(data=df, x='time_seconds', y='behavior', \n",
    "                hue='behavior', palette={'forward': 'green', 'backward': 'red', 'other': 'blue'},\n",
    "                s=100, alpha=0.7)\n",
    "plt.title('Bee Behavior Over Time', fontsize=16)\n",
    "plt.xlabel('Time (seconds)', fontsize=12)\n",
    "plt.ylabel('Behavior Type', fontsize=12)\n",
    "#plt.xticks(ticks=range(0, 61, 5))\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(ticks=range(240, 300, 10))  \n",
    "plt.xlim(240, 300)  \n",
    "\n",
    "\n",
    "# 2. Cumulative distribution\n",
    "if not df.empty:\n",
    "    \n",
    "    behavior_counts = df.groupby(['time_seconds', 'behavior']).size().unstack(fill_value=0)\n",
    "    \n",
    "    \n",
    "    for col in ['forward', 'backward', 'other']:\n",
    "        if col not in behavior_counts.columns:\n",
    "            behavior_counts[col] = 0\n",
    "    \n",
    "    \n",
    "    behavior_counts = behavior_counts.sort_index()\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    behavior_counts.cumsum().plot(\n",
    "        kind='line',\n",
    "        linewidth=2,\n",
    "        color={'forward': 'green', 'backward': 'red', 'other': 'blue'}\n",
    "    )\n",
    "    \n",
    "    plt.title('Cumulative Behavior Distribution', fontsize=16)\n",
    "    plt.xlabel('Time (seconds)', fontsize=12)\n",
    "    plt.ylabel('Total Detections', fontsize=12)\n",
    "    #plt.xticks(range(0, 61, 5))\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend(title='Behavior')\n",
    "    plt.show()\n",
    "    plt.xticks(ticks=range(240, 300, 10))  \n",
    "    plt.xlim(240, 300)  \n",
    "else:\n",
    "    print(\"Error: DataFrame is empty. Please check input data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2029691-5905-464a-8176-95536654ddf9",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a554bd-0dfe-403b-8f6b-d53a934a5189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow.keras.models import load_model\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize detection client\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=\"99oKvIcFbNcIWjEIglpT\"\n",
    ")\n",
    "\n",
    "# Load classification model\n",
    "MODEL_PATH = 'bee_classifier_909.keras'\n",
    "classifier = load_model(MODEL_PATH)\n",
    "\n",
    "# Video parameters\n",
    "video_path = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\gopro\\test.mp4\"\n",
    "output_dir = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Behavior classification function\n",
    "def classify_bee_behavior(cropped_bee_img, classifier_model, img_size=(128, 128)):\n",
    "    img = cv2.cvtColor(cropped_bee_img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    predictions = classifier_model.predict(img, verbose=0)\n",
    "    class_idx = np.argmax(predictions[0])\n",
    "    class_prob = np.max(predictions[0])\n",
    "    class_names = {0: 'forward', 1: 'backward', 2: 'other'}\n",
    "    \n",
    "    return {\n",
    "        'behavior': class_names[class_idx],\n",
    "        'confidence': float(class_prob)\n",
    "    }\n",
    "\n",
    "# Open video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(f\"Failed to open video {video_path}\")\n",
    "\n",
    "# Video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"FPS: {fps}, Total frames: {total_frames}\")\n",
    "\n",
    "# Calculate frame range (20s to 1:20)\n",
    "start_second = 20\n",
    "end_second = 80  # 1 minute 20 seconds\n",
    "start_frame = int(fps * start_second)\n",
    "end_frame = int(fps * end_second)\n",
    "end_frame = min(end_frame, total_frames)  # Don't exceed video length\n",
    "\n",
    "# Set starting position\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Processing parameters\n",
    "frame_count = start_frame\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "# Main processing loop\n",
    "while frame_count <= end_frame:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    current_time = frame_count / fps  # Current time in seconds\n",
    "    \n",
    "    # Detection on resized frame for performance\n",
    "    resized_frame = cv2.resize(frame, (640, 360))\n",
    "    detections = CLIENT.infer(resized_frame, model_id=\"test-tws1v/3\")\n",
    "    \n",
    "    # Scale coordinates back to original size\n",
    "    scale_x = frame.shape[1] / resized_frame.shape[1]\n",
    "    scale_y = frame.shape[0] / resized_frame.shape[0]\n",
    "    \n",
    "    for detection in detections[\"predictions\"]:\n",
    "        if detection[\"class\"].lower() == \"bee\" and detection[\"confidence\"] > 0.5:\n",
    "            # Get bounding box coordinates\n",
    "            x = int(detection[\"x\"] * scale_x)\n",
    "            y = int(detection[\"y\"] * scale_y)\n",
    "            width = int(detection[\"width\"] * scale_x)\n",
    "            height = int(detection[\"height\"] * scale_y)\n",
    "            \n",
    "            # Adjust coordinates\n",
    "            x1 = max(0, int(x - width/2))\n",
    "            y1 = max(0, int(y - height/2))\n",
    "            x2 = min(frame.shape[1], int(x + width/2))\n",
    "            y2 = min(frame.shape[0], int(y + height/2))\n",
    "            \n",
    "            # Extract bee region\n",
    "            bee_img = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            if bee_img.size == 0:\n",
    "                continue\n",
    "                \n",
    "            # Classify behavior\n",
    "            behavior = classify_bee_behavior(bee_img, classifier)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'frame': frame_count,\n",
    "                'time_seconds': current_time,\n",
    "                'behavior': behavior['behavior'],\n",
    "                'confidence': behavior['confidence'],\n",
    "                'detection_confidence': detection[\"confidence\"],\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "            \n",
    "            # Visualization (every 30 frames)\n",
    "            if frame_count % 30 == 0:\n",
    "                display_img = cv2.cvtColor(bee_img.copy(), cv2.COLOR_BGR2RGB)\n",
    "                time_str = str(timedelta(seconds=current_time))[2:7]  # MM:SS format\n",
    "                plt.imshow(display_img)\n",
    "                plt.title(f\"Frame {frame_count} ({time_str})\\n\"\n",
    "                         f\"Behavior: {behavior['behavior']} ({behavior['confidence']:.1%})\\n\"\n",
    "                         f\"Detection: {detection['confidence']:.1%}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            label = f\"{behavior['behavior']} {behavior['confidence']:.1%}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "    \n",
    "    # Print progress\n",
    "    if frame_count % 10 == 0:\n",
    "        time_str = str(timedelta(seconds=current_time))[2:7]\n",
    "        print(f\"Processed frame {frame_count} ({time_str})\")\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "processing_time = time.time() - start_time\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results)\n",
    "output_filename = f'behavior_analysis_test_forward.csv'\n",
    "results_df.to_csv(os.path.join(output_dir, output_filename), index=False)\n",
    "\n",
    "print(f\"\\nAnalysis completed in {processing_time:.1f} seconds\")\n",
    "print(f\"Total bees detected: {len(results)}\")\n",
    "print(f\"Results saved to {os.path.join(output_dir, output_filename)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541364f5-320b-4407-9116-cc5d1c578c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_test_forward.csv\")\n",
    "\n",
    "# Convert time to readable format\n",
    "df['time'] = df['time_seconds'].apply(lambda x: str(timedelta(seconds=x)))[2:7]\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# 1. Behavior distribution over time\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.scatterplot(data=df, x='time_seconds', y='behavior', \n",
    "                hue='behavior', palette={'forward': 'green', 'backward': 'red', 'other': 'blue'},\n",
    "                s=100, alpha=0.7)\n",
    "plt.title('Bee Behavior Over Time', fontsize=16)\n",
    "plt.xlabel('Time (seconds)', fontsize=12)\n",
    "plt.ylabel('Behavior Type', fontsize=12)\n",
    "#plt.xticks(ticks=range(0, 61, 5))\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(ticks=range(20, 80, 10))  \n",
    "plt.xlim(20, 80)  \n",
    "\n",
    "\n",
    "# 2. Cumulative distribution\n",
    "if not df.empty:\n",
    "    \n",
    "    behavior_counts = df.groupby(['time_seconds', 'behavior']).size().unstack(fill_value=0)\n",
    "    \n",
    "    for col in ['forward', 'backward', 'other']:\n",
    "        if col not in behavior_counts.columns:\n",
    "            behavior_counts[col] = 0\n",
    "    \n",
    "    \n",
    "    behavior_counts = behavior_counts.sort_index()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    behavior_counts.cumsum().plot(\n",
    "        kind='line',\n",
    "        linewidth=2,\n",
    "        color={'forward': 'green', 'backward': 'red', 'other': 'blue'}\n",
    "    )\n",
    "    \n",
    "    plt.title('Cumulative Behavior Distribution', fontsize=16)\n",
    "    plt.xlabel('Time (seconds)', fontsize=12)\n",
    "    plt.ylabel('Total Detections', fontsize=12)\n",
    "    #plt.xticks(range(0, 61, 5))\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend(title='Behavior')\n",
    "    plt.show()\n",
    "    plt.xticks(ticks=range(20, 80, 10))  \n",
    "    plt.xlim(20, 80)  \n",
    "else:\n",
    "    print(\"Error: DataFrame is empty. Please check input data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d20ed-06d9-4151-9f0c-38b11d596115",
   "metadata": {},
   "source": [
    "#### Backward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb63f4-0c06-4fef-86b3-ba939e237ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow.keras.models import load_model\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize detection client\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=\"99oKvIcFbNcIWjEIglpT\"\n",
    ")\n",
    "\n",
    "# Load classification model\n",
    "MODEL_PATH = 'bee_classifier_909.keras'\n",
    "classifier = load_model(MODEL_PATH)\n",
    "\n",
    "# Video parameters\n",
    "video_path = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\gopro\\test.mp4\"\n",
    "output_dir = r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Behavior classification function\n",
    "def classify_bee_behavior(cropped_bee_img, classifier_model, img_size=(128, 128)):\n",
    "    img = cv2.cvtColor(cropped_bee_img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    predictions = classifier_model.predict(img, verbose=0)\n",
    "    class_idx = np.argmax(predictions[0])\n",
    "    class_prob = np.max(predictions[0])\n",
    "    class_names = {0: 'forward', 1: 'backward', 2: 'other'}\n",
    "    \n",
    "    return {\n",
    "        'behavior': class_names[class_idx],\n",
    "        'confidence': float(class_prob)\n",
    "    }\n",
    "\n",
    "# Open video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(f\"Failed to open video {video_path}\")\n",
    "\n",
    "# Video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"FPS: {fps}, Total frames: {total_frames}\")\n",
    "\n",
    "# Calculate frame range (20s to 1:20)\n",
    "start_second = 232\n",
    "end_second = 292  # 1 minute 20 seconds\n",
    "start_frame = int(fps * start_second)\n",
    "end_frame = int(fps * end_second)\n",
    "end_frame = min(end_frame, total_frames)  # Don't exceed video length\n",
    "\n",
    "# Set starting position\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Processing parameters\n",
    "frame_count = start_frame\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "# Main processing loop\n",
    "while frame_count <= end_frame:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    current_time = frame_count / fps  # Current time in seconds\n",
    "    \n",
    "    # Detection on resized frame for performance\n",
    "    resized_frame = cv2.resize(frame, (640, 360))\n",
    "    detections = CLIENT.infer(resized_frame, model_id=\"test-tws1v/3\")\n",
    "    \n",
    "    # Scale coordinates back to original size\n",
    "    scale_x = frame.shape[1] / resized_frame.shape[1]\n",
    "    scale_y = frame.shape[0] / resized_frame.shape[0]\n",
    "    \n",
    "    for detection in detections[\"predictions\"]:\n",
    "        if detection[\"class\"].lower() == \"bee\" and detection[\"confidence\"] > 0.5:\n",
    "            # Get bounding box coordinates\n",
    "            x = int(detection[\"x\"] * scale_x)\n",
    "            y = int(detection[\"y\"] * scale_y)\n",
    "            width = int(detection[\"width\"] * scale_x)\n",
    "            height = int(detection[\"height\"] * scale_y)\n",
    "            \n",
    "            # Adjust coordinates\n",
    "            x1 = max(0, int(x - width/2))\n",
    "            y1 = max(0, int(y - height/2))\n",
    "            x2 = min(frame.shape[1], int(x + width/2))\n",
    "            y2 = min(frame.shape[0], int(y + height/2))\n",
    "            \n",
    "            # Extract bee region\n",
    "            bee_img = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            if bee_img.size == 0:\n",
    "                continue\n",
    "                \n",
    "            # Classify behavior\n",
    "            behavior = classify_bee_behavior(bee_img, classifier)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'frame': frame_count,\n",
    "                'time_seconds': current_time,\n",
    "                'behavior': behavior['behavior'],\n",
    "                'confidence': behavior['confidence'],\n",
    "                'detection_confidence': detection[\"confidence\"],\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "            \n",
    "            # Visualization (every 30 frames)\n",
    "            if frame_count % 30 == 0:\n",
    "                display_img = cv2.cvtColor(bee_img.copy(), cv2.COLOR_BGR2RGB)\n",
    "                time_str = str(timedelta(seconds=current_time))[2:7]  # MM:SS format\n",
    "                plt.imshow(display_img)\n",
    "                plt.title(f\"Frame {frame_count} ({time_str})\\n\"\n",
    "                         f\"Behavior: {behavior['behavior']} ({behavior['confidence']:.1%})\\n\"\n",
    "                         f\"Detection: {detection['confidence']:.1%}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            label = f\"{behavior['behavior']} {behavior['confidence']:.1%}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "    \n",
    "    # Print progress\n",
    "    if frame_count % 10 == 0:\n",
    "        time_str = str(timedelta(seconds=current_time))[2:7]\n",
    "        print(f\"Processed frame {frame_count} ({time_str})\")\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "processing_time = time.time() - start_time\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results)\n",
    "output_filename = f'behavior_analysis_test_backward.csv'\n",
    "results_df.to_csv(os.path.join(output_dir, output_filename), index=False)\n",
    "\n",
    "print(f\"\\nAnalysis completed in {processing_time:.1f} seconds\")\n",
    "print(f\"Total bees detected: {len(results)}\")\n",
    "print(f\"Results saved to {os.path.join(output_dir, output_filename)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79bd934-fa72-4af8-bf6c-8416f2b395da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_test_backward.csv\")\n",
    "\n",
    "# Convert time to readable format\n",
    "df['time'] = df['time_seconds'].apply(lambda x: str(timedelta(seconds=x)))[2:7]\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# 1. Behavior distribution over time\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.scatterplot(data=df, x='time_seconds', y='behavior', \n",
    "                hue='behavior', palette={'forward': 'green', 'backward': 'red', 'other': 'blue'},\n",
    "                s=100, alpha=0.7)\n",
    "plt.title('Bee Behavior Over Time', fontsize=16)\n",
    "plt.xlabel('Time (seconds)', fontsize=12)\n",
    "plt.ylabel('Behavior Type', fontsize=12)\n",
    "#plt.xticks(ticks=range(0, 61, 5))\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(ticks=range(232, 292, 10))  \n",
    "plt.xlim(232, 292)  \n",
    "\n",
    "\n",
    "# 2. Cumulative distribution\n",
    "if not df.empty:\n",
    "    \n",
    "    behavior_counts = df.groupby(['time_seconds', 'behavior']).size().unstack(fill_value=0)\n",
    "    \n",
    "    for col in ['forward', 'backward', 'other']:\n",
    "        if col not in behavior_counts.columns:\n",
    "            behavior_counts[col] = 0\n",
    "    \n",
    "    behavior_counts = behavior_counts.sort_index()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    behavior_counts.cumsum().plot(\n",
    "        kind='line',\n",
    "        linewidth=2,\n",
    "        color={'forward': 'green', 'backward': 'red', 'other': 'blue'}\n",
    "    )\n",
    "    \n",
    "    plt.title('Cumulative Behavior Distribution', fontsize=16)\n",
    "    plt.xlabel('Time (seconds)', fontsize=12)\n",
    "    plt.ylabel('Total Detections', fontsize=12)\n",
    "    #plt.xticks(range(0, 61, 5))\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend(title='Behavior')\n",
    "    plt.show()\n",
    "    plt.xticks(ticks=range(232, 292, 10))  \n",
    "    plt.xlim(232, 292)  \n",
    "else:\n",
    "    print(\"Error: DataFrame is empty. Please check input data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5de89e-2b93-4df9-b8be-590bdbe06b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_11s_to_71s.csv\")\n",
    "\n",
    "# Counting amounts of each state\n",
    "behavior_counts = data['behavior'].value_counts()\n",
    "\n",
    "print(behavior_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44481a06-8a79-4342-b784-c71c174a29d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "behavior_counts.plot(kind='bar', color=['blue', 'green', 'red'])\n",
    "plt.title('Behavior State Distribution (11s-71s)')\n",
    "plt.xlabel('Behavior State')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d81f465-c18f-46e6-abc7-1175fe6acc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load data from 4 files\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_11s_to_71s.csv\",\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_153s_to_217s.csv\",\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_test_3_9_10286_backward.csv\",\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_test_3_9_10286_forward.csv\"\n",
    "]\n",
    "\n",
    "# Create list to store data\n",
    "data_list = []\n",
    "for file_path in file_paths:\n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        behavior_counts = data['behavior'].value_counts()\n",
    "        data_list.append({\n",
    "            'filename': os.path.basename(file_path),\n",
    "            'forward': behavior_counts.get('forward', 0),\n",
    "            'backward': behavior_counts.get('backward', 0),\n",
    "            'other': behavior_counts.get('other', 0)\n",
    "        })\n",
    "    else:\n",
    "        print(f\"File {file_path} not found, skipping\")\n",
    "\n",
    "# Create DataFrame from collected data\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Configure plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "width = 0.2  # Bar width\n",
    "x = range(len(df))  # X-axis positions\n",
    "\n",
    "# Create bars for each behavior state\n",
    "bars1 = plt.bar([i - width for i in x], df['forward'], width, label='Forward', color='blue')\n",
    "bars2 = plt.bar(x, df['backward'], width, label='Backward', color='green')\n",
    "bars3 = plt.bar([i + width for i in x], df['other'], width, label='Other', color='red')\n",
    "\n",
    "# Configure axes and title\n",
    "plt.xlabel('Video and time segment')\n",
    "plt.ylabel('Number of occurrences')\n",
    "plt.title('Behavior state distribution across 4 video segments')\n",
    "plt.xticks(x, df['filename'], rotation=45, ha='right')\n",
    "plt.legend()\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{int(height)}',\n",
    "                 ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb5200e-3d93-470e-8d94-7ade9377f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load data from 4 files\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_11s_to_71s.csv\",\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_153s_to_217s.csv\",\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_test_3_9_10286_backward.csv\",\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_test_3_9_10286_forward.csv\"\n",
    "]\n",
    "\n",
    "# Create list to store data\n",
    "data_list = []\n",
    "for file_path in file_paths:\n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        behavior_counts = data['behavior'].value_counts()\n",
    "        data_list.append({\n",
    "            'filename': os.path.basename(file_path),\n",
    "            'forward': behavior_counts.get('forward', 0),\n",
    "            'backward': behavior_counts.get('backward', 0),\n",
    "            'other': behavior_counts.get('other', 0)\n",
    "        })\n",
    "    else:\n",
    "        print(f\"File {file_path} not found, skipping\")\n",
    "\n",
    "# Create DataFrame from collected data\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Plot configuration\n",
    "plt.figure(figsize=(12, 8))\n",
    "width = 0.2  # Column width\n",
    "x = range(len(df))  # X-axis positions\n",
    "\n",
    "# Create bars for each behavior state\n",
    "bars1 = plt.bar([i - width for i in x], df['forward'], width, label='Forward', color='blue')\n",
    "bars2 = plt.bar(x, df['backward'], width, label='Backward', color='green')\n",
    "bars3 = plt.bar([i + width for i in x], df['other'], width, label='Other', color='red')\n",
    "\n",
    "# Axis and title configuration\n",
    "plt.xlabel('Video and time segment')\n",
    "plt.ylabel('Count of occurrences')\n",
    "plt.title('Behavior state distribution across 4 video segments')\n",
    "plt.xticks(x, df['filename'], rotation=45, ha='right')\n",
    "plt.legend()\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{int(height)}',\n",
    "                 ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f53158-373d-4ab1-96cf-70c75361b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load data from 4 files\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_11s_to_71s.csv\",\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_153s_to_217s.csv\",\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_test_3_9_10286_backward.csv\",\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_test_3_9_10286_forward.csv\"\n",
    "]\n",
    "\n",
    "# Custom labels for each file\n",
    "custom_labels = [\n",
    "    \"GX010262_forward\",\n",
    "    \"GX010262_backward\",\n",
    "    \"GX010286_forward\",\n",
    "    \"GX010286_backward\"\n",
    "]\n",
    "\n",
    "# Create list to store data\n",
    "data_list = []\n",
    "for file_path in file_paths:\n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        behavior_counts = data['behavior'].value_counts()\n",
    "        data_list.append({\n",
    "            'filename': os.path.basename(file_path),\n",
    "            'forward': behavior_counts.get('forward', 0),\n",
    "            'backward': behavior_counts.get('backward', 0),\n",
    "            'other': behavior_counts.get('other', 0)\n",
    "        })\n",
    "    else:\n",
    "        print(f\"File {file_path} not found, skipping\")\n",
    "\n",
    "# Create DataFrame from collected data\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Plot configuration\n",
    "plt.figure(figsize=(12, 8))\n",
    "width = 0.2  # Column width\n",
    "x = range(len(df))  # X-axis positions\n",
    "\n",
    "# Create bars for each behavior state\n",
    "bars1 = plt.bar([i - width for i in x], df['forward'], width, label='Forward', color='blue')\n",
    "bars2 = plt.bar(x, df['backward'], width, label='Backward', color='green')\n",
    "bars3 = plt.bar([i + width for i in x], df['other'], width, label='Other', color='red')\n",
    "\n",
    "# Axis and title configuration\n",
    "plt.xlabel('Video Segments')\n",
    "plt.ylabel('Count of Occurrences')\n",
    "plt.title('Behavior State Distribution Across Video Segments')\n",
    "plt.xticks(x, custom_labels, rotation=45, ha='right')  # Using custom labels here\n",
    "plt.legend()\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{int(height)}',\n",
    "                 ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954673ff-1f14-4fce-b086-fe34eb6f2d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "\n",
    "# Load data from 4 files\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_11s_to_71s.csv\",\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_153s_to_217s.csv\",\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_test_3_9_10286_backward.csv\",\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_test_3_9_10286_forward.csv\"\n",
    "]\n",
    "\n",
    "# Custom labels and directions for each file\n",
    "custom_labels = [\n",
    "    \"GX010262_forward\",\n",
    "    \"GX010262_backward\",\n",
    "    \"GX010286_forward\",\n",
    "    \"GX010286_backward\"\n",
    "]\n",
    "\n",
    "directions = ['left', 'right', 'left', 'right']  # Arrow directions\n",
    "\n",
    "# Create list to store data\n",
    "data_list = []\n",
    "for file_path in file_paths:\n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        behavior_counts = data['behavior'].value_counts()\n",
    "        data_list.append({\n",
    "            'filename': os.path.basename(file_path),\n",
    "            'forward': behavior_counts.get('forward', 0),\n",
    "            'backward': behavior_counts.get('backward', 0),\n",
    "            'other': behavior_counts.get('other', 0)\n",
    "        })\n",
    "    else:\n",
    "        print(f\"File {file_path} not found, skipping\")\n",
    "\n",
    "# Create DataFrame from collected data\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Plot configuration\n",
    "plt.figure(figsize=(14, 8))\n",
    "width = 0.2  # Column width\n",
    "x = range(len(df))  # X-axis positions\n",
    "\n",
    "# Create bars for each behavior state\n",
    "bars1 = plt.bar([i - width for i in x], df['forward'], width, label='Forward', color='blue')\n",
    "bars2 = plt.bar(x, df['backward'], width, label='Backward', color='green')\n",
    "bars3 = plt.bar([i + width for i in x], df['other'], width, label='Other', color='red')\n",
    "\n",
    "# Add directional arrows below x-axis labels\n",
    "ax = plt.gca()\n",
    "for i, direction in enumerate(directions):\n",
    "    arrow_x = i\n",
    "    arrow_y = -0.15  # Position below x-axis labels\n",
    "    arrow_length = 0.5\n",
    "    \n",
    "    if direction == 'left':\n",
    "        arrow = FancyArrowPatch((arrow_x + arrow_length/2, arrow_y), \n",
    "                               (arrow_x - arrow_length/2, arrow_y),\n",
    "                               arrowstyle='->', mutation_scale=15, color='black')\n",
    "    else:  # right\n",
    "        arrow = FancyArrowPatch((arrow_x - arrow_length/2, arrow_y), \n",
    "                               (arrow_x + arrow_length/2, arrow_y),\n",
    "                               arrowstyle='->', mutation_scale=15, color='black')\n",
    "    \n",
    "    ax.add_patch(arrow)\n",
    "\n",
    "# Axis and title configuration\n",
    "plt.xlabel('Video Segments', labelpad=20)  # Add padding for arrows\n",
    "plt.ylabel('Count of Occurrences')\n",
    "plt.title('Behavior State Distribution with Optical Flow Direction')\n",
    "plt.xticks(x, custom_labels, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{int(height)}',\n",
    "                 ha='center', va='bottom')\n",
    "\n",
    "# Adjust layout to accommodate arrows\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30ce93-8268-4e86-8548-c98a30c4cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "\n",
    "# Load data from 4 files\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_11s_to_71s.csv\",\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_153s_to_217s.csv\",\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_test_3_9_10286_backward.csv\",\n",
    "    r\"C:\\Users\\prol-\\Documents\\Masters\\Thesis\\dataset_new\\behavior_analysis_test_3_9_10286_forward.csv\"\n",
    "]\n",
    "\n",
    "# Custom labels and directions for each file\n",
    "custom_labels = [\n",
    "    \"GX010262_forward\",\n",
    "    \"GX010262_backward\",\n",
    "    \"GX010286_forward\",\n",
    "    \"GX010286_backward\"\n",
    "]\n",
    "\n",
    "directions = ['left', 'right', 'left', 'right']  # Arrow directions\n",
    "\n",
    "# Create list to store data\n",
    "data_list = []\n",
    "for file_path in file_paths:\n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        behavior_counts = data['behavior'].value_counts()\n",
    "        data_list.append({\n",
    "            'filename': os.path.basename(file_path),\n",
    "            'forward': behavior_counts.get('forward', 0),\n",
    "            'backward': behavior_counts.get('backward', 0),\n",
    "            'other': behavior_counts.get('other', 0)\n",
    "        })\n",
    "    else:\n",
    "        print(f\"File {file_path} not found, skipping\")\n",
    "\n",
    "# Create DataFrame from collected data\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Plot configuration with larger figure size\n",
    "plt.figure(figsize=(14, 10))\n",
    "width = 0.2  # Column width\n",
    "x = range(len(df))  # X-axis positions\n",
    "\n",
    "# Create bars for each behavior state\n",
    "bars1 = plt.bar([i - width for i in x], df['forward'], width, label='Forward', color='blue')\n",
    "bars2 = plt.bar(x, df['backward'], width, label='Backward', color='green')\n",
    "bars3 = plt.bar([i + width for i in x], df['other'], width, label='Other', color='red')\n",
    "\n",
    "# Add bold directional arrows below x-axis labels\n",
    "ax = plt.gca()\n",
    "arrow_props = {\n",
    "    'arrowstyle': '->',\n",
    "    'mutation_scale': 30,  # Larger arrow head\n",
    "    'linewidth': 3,       # Thicker line\n",
    "    'color': 'darkred'    # Brighter color\n",
    "}\n",
    "\n",
    "for i, direction in enumerate(directions):\n",
    "    arrow_x = i\n",
    "    arrow_y = -0.25  # Lower position (further below x-axis)\n",
    "    arrow_length = 0.6  # Longer arrows\n",
    "    \n",
    "    if direction == 'left':\n",
    "        arrow = FancyArrowPatch((arrow_x + arrow_length/2, arrow_y), \n",
    "                               (arrow_x - arrow_length/2, arrow_y),\n",
    "                               **arrow_props)\n",
    "    else:  # right\n",
    "        arrow = FancyArrowPatch((arrow_x - arrow_length/2, arrow_y), \n",
    "                               (arrow_x + arrow_length/2, arrow_y),\n",
    "                               **arrow_props)\n",
    "    \n",
    "    ax.add_patch(arrow)\n",
    "\n",
    "# Axis and title configuration\n",
    "plt.xlabel('Video Segments', labelpad=30)  # Increased padding for lower arrows\n",
    "plt.ylabel('Count of Occurrences')\n",
    "plt.title('Behavior State Distribution with Optical Flow Direction', pad=20)\n",
    "plt.xticks(x, custom_labels, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{int(height)}',\n",
    "                 ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Adjust layout to accommodate lower arrows\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
